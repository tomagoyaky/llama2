#!/usr/bin/env python3
"""
Ollama Chat - ä¸€ä¸ªç®€å•çš„å‘½ä»¤è¡ŒèŠå¤©ç¨‹åº
è¿æ¥åˆ°æœ¬åœ°OllamaæœåŠ¡è¿›è¡Œå¯¹è¯
"""

import requests
import json
import sys
import os
import argparse
from typing import Dict, List, Optional

class OllamaChat:
    def __init__(self, base_url: str = "http://localhost:11434", model: str = "llama2"):
        """
        åˆå§‹åŒ–OllamaèŠå¤©å®¢æˆ·ç«¯
        
        Args:
            base_url: OllamaæœåŠ¡çš„åŸºç¡€URL
            model: ä½¿ç”¨çš„æ¨¡å‹åç§°
        """
        self.base_url = base_url.rstrip('/')
        self.model = model
        self.api_url = f"{self.base_url}/api/chat"
        self.history: List[Dict[str, str]] = []
        
    def check_connection(self) -> bool:
        """æ£€æŸ¥OllamaæœåŠ¡æ˜¯å¦å¯ç”¨"""
        try:
            response = requests.get(f"{self.base_url}/api/tags", timeout=5)
            return response.status_code == 200
        except requests.exceptions.RequestException:
            return False
    
    def get_available_models(self) -> List[str]:
        """è·å–å¯ç”¨çš„æ¨¡å‹åˆ—è¡¨"""
        try:
            response = requests.get(f"{self.base_url}/api/tags")
            if response.status_code == 200:
                data = response.json()
                return [model['name'] for model in data.get('models', [])]
            return []
        except requests.exceptions.RequestException:
            return []
    
    def send_message(self, message: str, stream: bool = True) -> Optional[str]:
        """
        å‘é€æ¶ˆæ¯åˆ°Ollamaå¹¶è·å–å›å¤
        
        Args:
            message: ç”¨æˆ·è¾“å…¥çš„æ¶ˆæ¯
            stream: æ˜¯å¦ä½¿ç”¨æµå¼å“åº”
            
        Returns:
            æ¨¡å‹çš„å›å¤å†…å®¹
        """
        payload = {
            "model": self.model,
            "messages": self.history + [{"role": "user", "content": message}],
            "stream": stream
        }
        
        try:
            if stream:
                return self._handle_streaming_response(payload)
            else:
                response = requests.post(self.api_url, json=payload, timeout=60)
                if response.status_code == 200:
                    data = response.json()
                    assistant_message = data['message']['content']
                    self.history.append({"role": "user", "content": message})
                    self.history.append({"role": "assistant", "content": assistant_message})
                    return assistant_message
                else:
                    print(f"é”™è¯¯: HTTP {response.status_code}")
                    return None
        except requests.exceptions.RequestException as e:
            print(f"è¿æ¥é”™è¯¯: {e}")
            return None
    
    def _handle_streaming_response(self, payload: Dict) -> Optional[str]:
        """å¤„ç†æµå¼å“åº”"""
        try:
            response = requests.post(self.api_url, json=payload, stream=True, timeout=60)
            if response.status_code != 200:
                print(f"é”™è¯¯: HTTP {response.status_code}")
                return None
            
            print("åŠ©æ‰‹: ", end="", flush=True)
            full_response = ""
            
            for line in response.iter_lines():
                if line:
                    try:
                        data = json.loads(line.decode('utf-8'))
                        if 'message' in data and 'content' in data['message']:
                            content = data['message']['content']
                            print(content, end="", flush=True)
                            full_response += content
                        if data.get('done', False):
                            break
                    except json.JSONDecodeError:
                        continue
            
            print()  # æ¢è¡Œ
            self.history.append({"role": "user", "content": payload["messages"][-1]["content"]})
            self.history.append({"role": "assistant", "content": full_response})
            return full_response
            
        except requests.exceptions.RequestException as e:
            print(f"è¿æ¥é”™è¯¯: {e}")
            return None
    
    def clear_history(self):
        """æ¸…é™¤å¯¹è¯å†å²"""
        self.history = []
        print("å¯¹è¯å†å²å·²æ¸…é™¤")
    
    def set_model(self, model: str):
        """è®¾ç½®ä½¿ç”¨çš„æ¨¡å‹"""
        available_models = self.get_available_models()
        if model in available_models:
            self.model = model
            print(f"å·²åˆ‡æ¢åˆ°æ¨¡å‹: {model}")
        else:
            print(f"æ¨¡å‹ {model} ä¸å¯ç”¨ã€‚å¯ç”¨æ¨¡å‹: {', '.join(available_models)}")
    
    def print_help(self):
        """æ‰“å°å¸®åŠ©ä¿¡æ¯"""
        print("""
å¯ç”¨å‘½ä»¤:
  /help     - æ˜¾ç¤ºæ­¤å¸®åŠ©ä¿¡æ¯
  /clear    - æ¸…é™¤å¯¹è¯å†å²
  /models   - æ˜¾ç¤ºå¯ç”¨æ¨¡å‹
  /model    - åˆ‡æ¢æ¨¡å‹ (ä¾‹å¦‚: /model llama2)
  /exit     - é€€å‡ºç¨‹åº
  /quit     - é€€å‡ºç¨‹åº
""")

def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='Ollama Chat - å‘½ä»¤è¡ŒèŠå¤©ç¨‹åº')
    parser.add_argument('--model', '-m', default='llama2', 
                        help='ä½¿ç”¨çš„æ¨¡å‹åç§° (é»˜è®¤: llama2)')
    parser.add_argument('--url', '-u', default='http://localhost:11434',
                        help='OllamaæœåŠ¡åœ°å€ (é»˜è®¤: http://localhost:11434)')
    parser.add_argument('--thinking', '-t', action='store_true',
                        help='å¯ç”¨thinkingæ¨¡å¼ (æ˜¾ç¤ºæ€è€ƒè¿‡ç¨‹)')
    parser.add_argument('--no-stream', action='store_true',
                        help='ç¦ç”¨æµå¼å“åº”')
    
    args = parser.parse_args()
    
    print("ğŸ¤– Ollama Chat - å‘½ä»¤è¡ŒèŠå¤©ç¨‹åº")
    print("=" * 50)
    
    # åˆå§‹åŒ–èŠå¤©å®¢æˆ·ç«¯
    chat = OllamaChat(base_url=args.url, model=args.model)
    
    # æ£€æŸ¥è¿æ¥
    if not chat.check_connection():
        print("âŒ æ— æ³•è¿æ¥åˆ°OllamaæœåŠ¡")
        print("è¯·ç¡®ä¿Ollamaæ­£åœ¨è¿è¡Œ: ollama serve")
        sys.exit(1)
    
    # è·å–å¯ç”¨æ¨¡å‹
    models = chat.get_available_models()
    if not models:
        print("âš ï¸  æ²¡æœ‰æ‰¾åˆ°å¯ç”¨çš„æ¨¡å‹")
        print("è¯·ä½¿ç”¨ 'ollama pull <model-name>' ä¸‹è½½æ¨¡å‹")
    else:
        print(f"âœ… å·²è¿æ¥åˆ°Ollamaï¼Œå¯ç”¨æ¨¡å‹: {', '.join(models)}")
        if chat.model not in models:
            print(f"âš ï¸  æŒ‡å®šæ¨¡å‹ {chat.model} ä¸å¯ç”¨ï¼Œä½¿ç”¨ç¬¬ä¸€ä¸ªå¯ç”¨æ¨¡å‹: {models[0]}")
            chat.model = models[0]
        print(f"å½“å‰ä½¿ç”¨æ¨¡å‹: {chat.model}")
    
    if args.thinking:
        print("ğŸ§  å·²å¯ç”¨thinkingæ¨¡å¼")
    
    print("\nè¾“å…¥ /help æŸ¥çœ‹å¯ç”¨å‘½ä»¤")
    print("è¾“å…¥ /exit æˆ– /quit é€€å‡ºç¨‹åº")
    print("-" * 50)
    
    # ä¸»å¾ªç¯
    while True:
        try:
            user_input = input("\nä½ : ").strip()
            
            if not user_input:
                continue
            
            # å¤„ç†å‘½ä»¤
            if user_input.startswith('/'):
                command = user_input.lower()
                
                if command in ['/exit', '/quit']:
                    print("ğŸ‘‹ å†è§ï¼")
                    break
                elif command == '/help':
                    chat.print_help()
                elif command == '/clear':
                    chat.clear_history()
                elif command == '/models':
                    models = chat.get_available_models()
                    print(f"å¯ç”¨æ¨¡å‹: {', '.join(models)}")
                elif command.startswith('/model '):
                    model_name = user_input[7:].strip()
                    chat.set_model(model_name)
                else:
                    print("æœªçŸ¥å‘½ä»¤ï¼Œè¾“å…¥ /help æŸ¥çœ‹å¯ç”¨å‘½ä»¤")
                continue
            
            # å‘é€æ¶ˆæ¯
            response = chat.send_message(user_input, stream=not args.no_stream)
            if response is None:
                print("âŒ è·å–å›å¤å¤±è´¥ï¼Œè¯·æ£€æŸ¥OllamaæœåŠ¡çŠ¶æ€")
                
        except KeyboardInterrupt:
            print("\n\nğŸ‘‹ å†è§ï¼")
            break
        except EOFError:
            print("\n\nğŸ‘‹ å†è§ï¼")
            break

if __name__ == "__main__":
    main()
