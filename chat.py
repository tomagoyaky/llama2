#!/usr/bin/env python3
"""
Ollama Chat - ä¸€ä¸ªç®€å•çš„å‘½ä»¤è¡ŒèŠå¤©ç¨‹åº
è¿æ¥åˆ°æœ¬åœ°OllamaæœåŠ¡è¿›è¡Œå¯¹è¯
"""

import requests
import json
import sys
import os
import argparse
from typing import Dict, List, Optional

class OllamaChat:
    def __init__(self, base_url: str = "http://localhost:11434", model: str = "qwen3:0.6b"):
        """
        åˆå§‹åŒ–OllamaèŠå¤©å®¢æˆ·ç«¯
        
        Args:
            base_url: OllamaæœåŠ¡çš„åŸºç¡€URL
            model: ä½¿ç”¨çš„æ¨¡å‹åç§°
        """
        self.base_url = base_url.rstrip('/')
        self.model = model
        self.api_url = f"{self.base_url}/api/chat"
        self.history: List[Dict[str, str]] = []
        
    def check_connection(self) -> bool:
        """æ£€æŸ¥OllamaæœåŠ¡æ˜¯å¦å¯ç”¨"""
        try:
            response = requests.get(f"{self.base_url}/api/tags", timeout=5)
            return response.status_code == 200
        except requests.exceptions.RequestException:
            return False
    
    def get_available_models(self) -> List[str]:
        """è·å–å¯ç”¨çš„æ¨¡å‹åˆ—è¡¨"""
        try:
            response = requests.get(f"{self.base_url}/api/tags")
            if response.status_code == 200:
                data = response.json()
                return [model['name'] for model in data.get('models', [])]
            return []
        except requests.exceptions.RequestException:
            return []
    
    def send_message(self, message: str, stream: bool = True) -> Optional[str]:
        """
        å‘é€æ¶ˆæ¯åˆ°Ollamaå¹¶è·å–å›å¤
        
        Args:
            message: ç”¨æˆ·è¾“å…¥çš„æ¶ˆæ¯
            stream: æ˜¯å¦ä½¿ç”¨æµå¼å“åº”
            
        Returns:
            æ¨¡å‹çš„å›å¤å†…å®¹
        """
        payload = {
            "model": self.model,
            "messages": self.history + [{"role": "user", "content": message}],
            "stream": stream
        }
        
        try:
            if stream:
                return self._handle_streaming_response(payload)
            else:
                response = requests.post(self.api_url, json=payload, timeout=60)
                if response.status_code == 200:
                    data = response.json()
                    assistant_message = data['message']['content']
                    self.history.append({"role": "user", "content": message})
                    self.history.append({"role": "assistant", "content": assistant_message})
                    return assistant_message
                else:
                    print(f"é”™è¯¯: HTTP {response.status_code}")
                    return None
        except requests.exceptions.RequestException as e:
            print(f"è¿æ¥é”™è¯¯: {e}")
            return None
    
    def _handle_streaming_response(self, payload: Dict) -> Optional[str]:
        """å¤„ç†æµå¼å“åº”"""
        try:
            response = requests.post(self.api_url, json=payload, stream=True, timeout=60)
            if response.status_code != 200:
                print(f"é”™è¯¯: HTTP {response.status_code}")
                return None
            
            print("åŠ©æ‰‹: ", end="", flush=True)
            full_response = ""
            
            for line in response.iter_lines():
                if line:
                    try:
                        data = json.loads(line.decode('utf-8'))
                        if 'message' in data and 'content' in data['message']:
                            content = data['message']['content']
                            print(content, end="", flush=True)
                            full_response += content
                        if data.get('done', False):
                            break
                    except json.JSONDecodeError:
                        continue
            
            print()  # æ¢è¡Œ
            self.history.append({"role": "user", "content": payload["messages"][-1]["content"]})
            self.history.append({"role": "assistant", "content": full_response})
            return full_response
            
        except requests.exceptions.RequestException as e:
            print(f"è¿æ¥é”™è¯¯: {e}")
            return None
    
    def clear_history(self):
        """æ¸…é™¤å¯¹è¯å†å²"""
        self.history = []
        print("å¯¹è¯å†å²å·²æ¸…é™¤")
    
    def set_model(self, model: str):
        """è®¾ç½®ä½¿ç”¨çš„æ¨¡å‹"""
        available_models = self.get_available_models()
        if model in available_models:
            self.model = model
            print(f"å·²åˆ‡æ¢åˆ°æ¨¡å‹: {model}")
        else:
            print(f"æ¨¡å‹ {model} ä¸å¯ç”¨ã€‚å¯ç”¨æ¨¡å‹: {', '.join(available_models)}")
    
    def print_help(self):
        """æ‰“å°å¸®åŠ©ä¿¡æ¯"""
        print("""
å¯ç”¨å‘½ä»¤:
  /help     - æ˜¾ç¤ºæ­¤å¸®åŠ©ä¿¡æ¯
  /clear    - æ¸…é™¤å¯¹è¯å†å²
  /models   - æ˜¾ç¤ºå¯ç”¨æ¨¡å‹
  /model    - åˆ‡æ¢æ¨¡å‹ (ä¾‹å¦‚: /model qwen3:0.6b)
  /exit     - é€€å‡ºç¨‹åº
  /quit     - é€€å‡ºç¨‹åº
""")

def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='Ollama Chat - å‘½ä»¤è¡ŒèŠå¤©ç¨‹åº')
    parser.add_argument('--model', '-m', default='qwen3:0.6b', 
                        help='ä½¿ç”¨çš„æ¨¡å‹åç§° (é»˜è®¤: qwen3:0.6b)')
    parser.add_argument('--url', '-u', default='http://localhost:11434',
                        help='OllamaæœåŠ¡åœ°å€ (é»˜è®¤: http://localhost:11434)')
    parser.add_argument('--thinking', '-t', action='store_true',
                        help='å¯ç”¨thinkingæ¨¡å¼ (æ˜¾ç¤ºæ€è€ƒè¿‡ç¨‹)')
    parser.add_argument('--no-stream', action='store_true',
                        help='ç¦ç”¨æµå¼å“åº”')
    
    args = parser.parse_args()
    
    print("ğŸ¤– Ollama Chat - å‘½ä»¤è¡ŒèŠå¤©ç¨‹åº")
    print("=" * 50)
    
    # åˆå§‹åŒ–èŠå¤©å®¢æˆ·ç«¯
    chat = OllamaChat(base_url=args.url, model=args.model)
    
    # æ£€æŸ¥è¿æ¥
    if not chat.check_connection():
        print("âŒ æ— æ³•è¿æ¥åˆ°OllamaæœåŠ¡")
        print("è¯·ç¡®ä¿Ollamaæ­£åœ¨è¿è¡Œ: ollama serve")
        sys.exit(1)
    
    # è·å–å¯ç”¨æ¨¡å‹
    models = chat.get_available_models()
    if not models:
        print("âš ï¸  æ²¡æœ‰æ‰¾åˆ°å¯ç”¨çš„æ¨¡å‹")
        print("è¯·ä½¿ç”¨ 'ollama pull <model-name>' ä¸‹è½½æ¨¡å‹")
    else:
        print(f"âœ… å·²è¿æ¥åˆ°Ollamaï¼Œå¯ç”¨æ¨¡å‹: {', '.join(models)}")
        if chat.model not in models:
            print(f"âš ï¸  æŒ‡å®šæ¨¡å‹ {chat.model} ä¸å¯ç”¨ï¼Œä½¿ç”¨ç¬¬ä¸€ä¸ªå¯ç”¨æ¨¡å‹: {models[0]}")
            chat.model = models[0]
        print(f"å½“å‰ä½¿ç”¨æ¨¡å‹: {chat.model}")
    
    if args.thinking:
        print("ğŸ§  å·²å¯ç”¨thinkingæ¨¡å¼")
    
    print("\nè¾“å…¥ /help æŸ¥çœ‹å¯ç”¨å‘½ä»¤")
    print("è¾“å…¥ /exit æˆ– /quit é€€å‡ºç¨‹åº")
    print("-" * 50)
    
    # Send default first input automatically
    default_input = "å¸®æˆ‘åˆ›å»ºä¸€ä¸ªhelloworld.cç¨‹åºæ–‡ä»¶"
    print(f"\nYou: {default_input}")
    wrapped_prompt = (
        f"ä½ æ˜¯ä¸€ä¸ªæ–‡ä»¶ç”ŸæˆåŠ©æ‰‹ã€‚è¯·æ ¹æ®ä»¥ä¸‹ç”¨æˆ·éœ€æ±‚ï¼Œç”Ÿæˆæ–‡ä»¶åå’Œæ–‡ä»¶å†…å®¹ã€‚"
        f"è¾“å‡ºå¿…é¡»ä¸¥æ ¼éµå¾ªå¦‚ä¸‹æ ¼å¼ï¼š\n"
        f"æ–‡ä»¶å: <æ–‡ä»¶å>\nå†…å®¹:\n<æ–‡ä»¶å†…å®¹>\n"
        f"ç”¨æˆ·éœ€æ±‚: {default_input}\n"
        f"ä¸è¦è¾“å‡ºä»»ä½•è§£é‡Šæˆ–å¤šä½™æ–‡æœ¬ï¼Œåªè¾“å‡ºæŒ‡å®šæ ¼å¼çš„æ–‡ä»¶åå’Œå†…å®¹ã€‚"
    )
    print("[DEBUG] Wrapped prompt sent to Ollama:\n" + wrapped_prompt)
    response = chat.send_message(wrapped_prompt, stream=not args.no_stream)
    if response is None:
        print("âŒ Failed to get response. Please check Ollama service status.")
    else:
        import re
        file_match = re.search(r'File(?:name)?:\s*(.+?)\n+Content:?\s*\n([\s\S]+)', response)
        if file_match:
            filename = file_match.group(1).strip()
            filecontent = file_match.group(2).strip()
            try:
                with open(filename, 'w', encoding='utf-8') as f:
                    f.write(filecontent)
                print(f"[Local file created: {filename}]")
            except Exception as e:
                print(f"[Failed to write file {filename}: {e}]")
        else:
            print("[No valid file output detected. Please check your prompt or model reply format.]")

    # Main loop
    while True:
        try:
            user_input = input("\nYou: ").strip()

            if not user_input:
                continue

            # Handle commands
            if user_input.startswith('/'):
                command = user_input.lower()

                if command in ['/exit', '/quit']:
                    print("ğŸ‘‹ Bye!")
                    break
                elif command == '/help':
                    chat.print_help()
                elif command == '/clear':
                    chat.clear_history()
                elif command == '/models':
                    models = chat.get_available_models()
                    print(f"Available models: {', '.join(models)}")
                elif command.startswith('/model '):
                    model_name = user_input[7:].strip()
                    chat.set_model(model_name)
                else:
                    print("Unknown command. Type /help for available commands.")
                continue

            # ç”¨ä¸­æ–‡å°è£…ç”¨æˆ·è¾“å…¥ï¼Œè¦æ±‚ Ollama ä¸¥æ ¼è¾“å‡ºæ–‡ä»¶åå’Œå†…å®¹
            wrapped_prompt = (
                f"ç”¨æˆ·éœ€æ±‚: {user_input}\n"
                f"ä½ æ˜¯ä¸€ä¸ªæ–‡ä»¶ç”ŸæˆåŠ©æ‰‹ã€‚è¯·æ ¹æ®ä»¥ä¸‹ç”¨æˆ·éœ€æ±‚ï¼Œç”Ÿæˆæ–‡ä»¶åå’Œæ–‡ä»¶å†…å®¹ã€‚"
                f"è¾“å‡ºå¿…é¡»ä¸¥æ ¼éµå¾ªå¦‚ä¸‹æ ¼å¼ï¼š\n"
                f"æ–‡ä»¶å: <æ–‡ä»¶å>\nå†…å®¹:\n<æ–‡ä»¶å†…å®¹>\n"
                f"ä¸è¦è¾“å‡ºä»»ä½•è§£é‡Šæˆ–å¤šä½™æ–‡æœ¬ï¼Œåªè¾“å‡ºæŒ‡å®šæ ¼å¼çš„æ–‡ä»¶åå’Œå†…å®¹ã€‚"
            )

            # Debug info: show the actual prompt sent to Ollama
            print("[DEBUG] Wrapped prompt sent to Ollama:\n" + wrapped_prompt)
            print("-----------------------------------------------------------------------")

            response = chat.send_message(wrapped_prompt, stream=not args.no_stream)
            if response is None:
                print("âŒ Failed to get response. Please check Ollama service status.")
                continue

            # Parse Ollama response for file creation
            import re
            file_match = re.search(r'File(?:name)?:\s*(.+?)\n+Content:?\s*\n([\s\S]+)', response)
            if file_match:
                filename = file_match.group(1).strip()
                filecontent = file_match.group(2).strip()
                try:
                    with open(filename, 'w', encoding='utf-8') as f:
                        f.write(filecontent)
                    print(f"[Local file created: {filename}]")
                except Exception as e:
                    print(f"[Failed to write file {filename}: {e}")
            else:
                print("[No valid file output detected. Please check your prompt or model reply format.]")

        except KeyboardInterrupt:
            print("\n\nğŸ‘‹ Bye!")
            break
        except EOFError:
            print("\n\nğŸ‘‹ Bye!")
            break

if __name__ == "__main__":
    main()
